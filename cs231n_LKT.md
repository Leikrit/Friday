<center><font size="20">CS231n课程笔记翻译</font><br/></center>

<center><font size="5">By Leikrit莱克里特</font><br/></center>

[toc]

# 图像分类·Image Classification

**目标** 

在本节中，我们将介绍图像分类问题，这是从固定的类别集中为输入图像分配一个标签的任务。<mark>这是计算机视觉的核心问题之一</mark>，尽管它很简单，但有各种各样的实际应用。此外，正如我们将在后面的课程中看到的，许多其他看起来不同的计算机视觉任务(如物体检测，分割)可以简化为图像分类。

***

**挑战**

由于识别视觉概念(例如猫)的任务对人类来说是相对微不足道的，因此从计算机视觉算法的角度考虑所涉及的挑战是值得注意的。我们给出下面的挑战列表，请记住原始的图像被表示为以亮度为值的三维数组:

- **角度变化**。一个对象的单个实例可以相对于相机以多种方式定向。

- **缩放变化**。视觉类通常在大小上有变化(此处大小是指现实世界中的大小，而不仅仅是它们在图像中的范围)。

- **变形**。我们感兴趣的许多物体都不是刚体，它们可以以极端的方式变形。

- **遮挡**。感兴趣的物体可以被遮挡。有时一个物体只有一小部分(只有几个像素)是可见的。

- **照明条件**。光照对像素水平的影响是剧烈的。

- **背景杂波**。感兴趣的物体可能会融入它们所处的环境，使它们难以识别。

- **内部类变化**。感兴趣的事物的类别通常是相对广泛的，比如椅子。这些物体有许多不同类型，每一种都有自己的外观。

一个好的图像分类模型必须对所有这些变化的叉乘保持不变，同时保持对类间变化的敏感性。

<br/>

![图片](https://cs231n.github.io/assets/challenges.jpeg)

***

**数据驱动的方法**

我们该如何编写一个算法来将图像划分为不同的类别呢?与编写算法不同，例如，对数字列表排序，如何编写识别图像中的猫的算法并不明显。因此，我们不会试图直接在代码中指定每个感兴趣的类别是什么样子，我们将采取的方法与你对小孩采取的方法没有什么不同:我们将为计算机提供每个类的许多示例，然后开发学习算法，通过查看这些示例，了解每个类的视觉外观。这种方法被称为<mark>数据驱动方法</mark>，因为它依赖于首先积累标记图像的<mark>训练数据集（training dataset）</mark>。下面是这样一个数据集的一个例子:

<br/>

![图片](https://cs231n.github.io/assets/trainset.jpg)

***

**图像分类流程**

我们已经看到，图像分类中的任务是取一个像素数组，来表示一个图像，并为它分配一个标签。完整的图像分类流程可以规范化如下:


- **输入**:我们的输入由一组N张图片组成，每张图片都标记了K个不同的类别中的一个。我们把这些数据称为<mark>训练集（training set）</mark>。

- **学习**:我们的任务是使用训练集来了解每个类的样子。我们把这一步称为<mark>训练分类器（training a classifier）</mark>，或<mark>学习模型（learning a model）</mark>。

- **评估**:最后，我们通过要求分类器预测一组以前从未见过的新图像的标签来评估分类器的质量。然后，我们将这些图像的真实标签与分类器预测的标签进行比较。直观地说，我们希望更多的预测与真实答案(我们称之为<mark>基本事实（ground truth）</mark>)相匹配。

***

## 最近邻分类器·Nearest Neighbor Classifier

作为我们的第一个方法，我们将开发所谓的**最近邻分类器**。这个分类器与卷积神经网络无关，在实践中很少使用，但它可以让我们了解图像分类问题的基本方法。

***

**示例图像分类数据集:CIFAR-10**

一个流行的玩具图像分类数据集是[CIFAR-10数据集](https://www.cs.toronto.edu/~kriz/cifar.html)。这个数据集由60,000张32像素高和宽的小图像组成。每张图像被标记为10个类别中的一个(例如“飞机、汽车、鸟等”)。这6万张图像被划分为5万张图像的训练集和1万张图像的测试集。在下面的图像中，你可以看到10个随机的示例图像，分别来自10个类:

<br/>

![图片](https://cs231n.github.io/assets/nn.jpg)
<center><font size="3">左:来自CIFAR-10数据集的示例图像。右:第一列显示了一些测试图像，在每个测试图像旁边，我们根据像素差异显示了训练集中前10个最近的邻居。</font><br/></center>

***

假设现在我们得到了包含50,000张图像的CIFAR-10训练集(每个标签对应5,000张图像)，我们希望标记剩下的10,000张图像。最近邻分类器将取一张测试图像，将其与每一张训练图像进行比较，并预测最接近的训练图像的标签。在右上图中，您可以看到该过程的10个示例测试图像的示例结果。请注意，在10个示例中只有大约3个检索到同一类的图像，而在其他7个示例中情况并非如此。例如，在第8行中，距离马头最近的训练图像是一辆红色的汽车，可能是由于强烈的黑色背景。因此，在这种情况下，这张马的图像会被错误地标记为汽车。

您可能已经注意到，我们没有详细说明如何比较两张图像，在这种情况下，这只是两个32 x 32 x 3的块。最简单的方法之一是逐个像素地比较图像，并将所有的差异相加。换句话说，给定两个图像并用向量$ I_1,I_2 $表示它们，比较它们的一个合理选择可能是**L1距离（L1 distance）**:

$$ d_1(I_1,I_2)=\sum_p|I_1^p-I_2^p| $$

即对所有像素求和。下面是可视化的过程:

<br/>

![图片](https://cs231n.github.io/assets/nneg.jpeg)

<center><font size="3">一个使用像素差异来比较L1距离的两张图像的示例(本例中为一个颜色通道)。两幅图像按元素进行相减，然后将所有差值相加为一个数字。如果两幅图像完全相同，结果将为零。但如果图像非常不同，结果就会很大。</font><br/></center>

***

让我们再看看如何在代码中实现分类器。首先，让我们将CIFAR-10数据作为4个数组加载到内存中:训练数据、标签和测试数据、标签。在下面的代码中，```Xtr```(大小为50,000 x 32 x 32 x 3)保存训练集中的所有图像，对应的一维数组```Ytr```(长度为50,000)保存训练标签(从0到9):

```python
Xtr, Ytr, Xte, Yte = load_CIFAR10('data/cifar10/') # a magic function we provide
# flatten out all images to be one-dimensional
Xtr_rows = Xtr.reshape(Xtr.shape[0], 32 * 32 * 3) # Xtr_rows becomes 50000 x 3072
Xte_rows = Xte.reshape(Xte.shape[0], 32 * 32 * 3) # Xte_rows becomes 10000 x 3072
```

现在我们把所有的图像都拉伸成行，下面是我们如何训练和评估一个分类器:

```python
nn = NearestNeighbor() # create a Nearest Neighbor classifier class
nn.train(Xtr_rows, Ytr) # train the classifier on the training images and labels
Yte_predict = nn.predict(Xte_rows) # predict labels on the test images
# and now print the classification accuracy, which is the average number
# of examples that are correctly predicted (i.e. label matches)
print 'accuracy: %f' % ( np.mean(Yte_predict == Yte) )
```

请注意，作为评估标准，通常使用**准确度（accuracy）**，用于衡量预测正确的比例。请注意，我们将构建的所有分类器都满足这个通用API:它们都有一个```train(X,y)```函数，该函数接受要学习的数据和标签。在内部，该类应该构建某种标签模型，以及如何从数据中预测它们。然后有一个```predict(X)```函数，它接受新数据并预测标签。当然，我们忽略了最重要的部分——实际的分类器本身。下面是一个简单的最近邻分类器的实现，它的L1距离满足这个模板:

```python
import numpy as np

class NearestNeighbor(object):
  def __init__(self):
    pass

  def train(self, X, y):
    """ X is N x D where each row is an example. Y is 1-dimension of size N """
    # the nearest neighbor classifier simply remembers all the training data
    self.Xtr = X
    self.ytr = y

  def predict(self, X):
    """ X is N x D where each row is an example we wish to predict label for """
    num_test = X.shape[0]
    # lets make sure that the output type matches the input type
    Ypred = np.zeros(num_test, dtype = self.ytr.dtype)

    # loop over all test rows
    for i in range(num_test):
      # find the nearest training image to the i'th test image
      # using the L1 distance (sum of absolute value differences)
      distances = np.sum(np.abs(self.Xtr - X[i,:]), axis = 1)
      min_index = np.argmin(distances) # get the index with smallest distance
      Ypred[i] = self.ytr[min_index] # predict the label of the nearest example

    return Ypred
```

如果运行这段代码，您将看到该分类器在CIFAR-10上仅达到**38.6%**。这比随机猜测更令人印象深刻(随机猜测的准确率为10%，因为有10个类别)，但远不及人类的表现([估计约为94%](https://karpathy.github.io/2011/04/27/manually-classifying-cifar10/))，也远不及最先进的卷积神经网络，达到约95%，与人类的准确率相当(参考在最近Kaggle关于CIFAR-10的比赛的[排行榜](https://www.kaggle.com/c/cifar-10/leaderboard))。

***

**距离的选择**

还有很多计算向量间距离的方法。另一个常见的选择是使用**L2距离（L2 distance）**，它具有计算两个向量之间欧几里得距离的几何解释。距离的表达式是:

$$ d_2(I_1,I_2)=\sqrt{\sum_p (I_1^p-I_2^p)^2} $$

换句话说，我们将像以前一样计算像素级的差，但这一次我们将它们全部平方，加起来，最后取平方根。在numpy中，延用上面的代码只需要替换一行，也就是计算距离的那行:

```python
distances = np.sqrt(np.sum(np.square(self.Xtr - X[i,:]), axis = 1))
```

注意，我们包含了```np,sqtr```。但在实际的最近邻应用程序中，我们可以省略取平方根操作，因为平方根是一个**单调函数（monotonic function）**。也就是说，它按距离的绝对大小缩放，但它保持了相对顺序不变，所以最近邻算法有或没有取平方根的效果是相同的。如果您在CIFAR-10上运行这个距离的最近邻分类器，您将获得 **35.4%** 的准确率(略低于L1距离的结果)。

***

**L1与L2**

考虑这两个指标之间的差异是很有趣的。特别是，当涉及到两个向量之间的差异时，L2距离比L1距离更难以容忍。也就是说，L2距离更喜欢许多中等分歧而不是一个大分歧。L1和L2距离(或等价于一对图像之间差异的L1、L2范数)是 [p范数（p-norm）](https://planetmath.org/vectorpnorm) 最常用的特殊情况。

***

## K-最近邻分类器·k - Nearest Neighbor Classifier

您可能已经注意到，当我们希望进行预测时，只使用最近的图像的标签是很奇怪的。事实上，使用所谓的 **k-最近邻分类器（k-Nearest Neighbor Classifier）** 几乎总是可以做得更好。这个想法很简单:我们不是在训练集中寻找最接近的一张图像，而是找到最接近的**k**张图像，并让他们投票决定测试图像的标签。特别地，当k = 1时，我们又回到了最近邻分类器。直观地说，较高的k值具有平滑效果，使分类器更能抵抗异常值:

<br/>

![图片](https://cs231n.github.io/assets/knn.jpeg)

<center><font size="3">最近邻分类器和5-最近邻分类器之间的差异示例，使用二维点和3个类(红、蓝、绿)。彩色区域表示分类器诱导的L2距离的<mark>决策边界（decision boundaries）</mark>。白色区域表示分类不明确的点(即至少两个类别的投票是相同的)。注意，在NN分类器的情况下，离群数据点(例如蓝色点云中间的绿点)会产生可能不正确的预测的小岛屿，而5-NN分类器会平滑这些不规则性，可能会导致测试数据更好的<mark>泛化（generalization）</mark>(未显示)。还要注意，5-NN图像中的灰色区域是由最近邻之间的投票关系引起的(例如，两个邻居是红色的，接下来的两个邻居是蓝色的，最后一个邻居是绿色的)。</font><br/></center>

<br/>

在实践中，您总会希望使用k-最近邻分类器。但是k的值应该是多少呢?我们接下来讨论这个问题。

***

## 用于超参数调优的验证集·Validation sets for Hyperparameter tuning

k-最近邻分类器需要设置k。但是设置哪个数效果最好呢?此外，我们看到有许多不同的距离函数可以使用:L1范数，L2范数，还有许多其他我们甚至没有考虑到的选择(例如点积)。这些选择被称为**超参数（hyperparameters）**，它们经常出现在许多从数据中学习的机器学习算法的设计中。不过，应该选择什么值或配置通常并不明显。

您可能会建议我们应该尝试许多不同的值，看看哪种效果最好。这是一个很好的想法，这确实是我们要做的，但这必须非常谨慎。特别是，我们<mark>**不能将测试集用于调整超参数**</mark>。当你在设计机器学习算法时，你应该把测试集看作是一种非常宝贵的资源，理想情况下，在最后的最后之前都不应该碰它。否则，真正的危险是您可能会调优超参数以使其在测试集上能够很好地运作，但如果您要部署模型，则可能会看到性能显著降低。在实践中，我们会说你对测试集**过度拟合（overfit）**。另一种看待它的方式是，如果你在测试集上调优你的超参数，你实际上是在把测试集用作训练集，因此你在测试集上获得的性能与你部署模型时可能实际观察到的情况相比过于乐观。但是如果你只在最后使用一次测试集，它仍然是衡量分类器泛化的一个很好的代理(我们将在后面的课程中看到更多关于泛化的讨论)。

> 在最后的最后才能把模型用于评估测试集，而且只能评估一次。

幸运的是，有一种调整超参数的正确方法，它根本不涉及测试集。我们的想法是把我们的训练集分成两个:一个稍微小一点的训练集，另一个我们称之为**验证集（validation set）**。以CIFAR-10为例，我们可以使用49,000张训练图像进行训练，并保留1,000张用于验证。这个验证集本质上是作为一个假测试集来调优超参数。

以下是CIFAR-10的情况:

```python
# assume we have Xtr_rows, Ytr, Xte_rows, Yte as before
# recall Xtr_rows is 50,000 x 3072 matrix
Xval_rows = Xtr_rows[:1000, :] # take first 1000 for validation
Yval = Ytr[:1000]
Xtr_rows = Xtr_rows[1000:, :] # keep last 49,000 for train
Ytr = Ytr[1000:]

# find hyperparameters that work best on the validation set
validation_accuracies = []
for k in [1, 3, 5, 10, 20, 50, 100]:

  # use a particular value of k and evaluation on validation data
  nn = NearestNeighbor()
  nn.train(Xtr_rows, Ytr)
  # here we assume a modified NearestNeighbor class that can take a k as input
  Yval_predict = nn.predict(Xval_rows, k = k)
  acc = np.mean(Yval_predict == Yval)
  print 'accuracy: %f' % (acc,)

  # keep track of what works on the validation set
  validation_accuracies.append((k, acc))
```

在这个过程结束时，我们可以绘制一个图表，显示k的哪个值最好。然后，我们将继续使用这个值，并在实际测试集上评估一次。

> 把你的训练集分成训练集和验证集。使用验证集调优所有超参数。最后在测试集上运行一次并报告性能。

***

**交叉验证法·Cross-validation**

在训练数据的大小(验证数据同理)可能很小的情况下，人们有时会使用一种更复杂的技术来进行超参数调优，称为**交叉验证（cross-validation）**。延用我们前面的例子，我们的想法是，不是任意地选择前1000个数据点作为验证集和其余训练集，而是通过迭代不同的验证集并将这些验证集的性能取平均。这样可以更好且更精准地估计某个k的值的工作效果。例如，在5次交叉验证中，我们将训练数据分成5次相等的**折叠（fold）**，其中4次用于训练，1次用于验证。然后我们将迭代哪个折叠是验证折叠，评估性能，最后在不同的折叠上平均性能。

<br/>

![图片](https://cs231n.github.io/assets/cvplot.png)

<center><font size="3">参数k的5次交叉验证运行示例。对于每个k的值，我们在训练4次，并在第5次折叠上计算。因此，对于每个k，我们在验证折叠上获得5个精度(精度是y轴，每个结果是一个点)。趋势线是通过每个k的结果的平均值绘制的，误差条表示标准偏差。请注意，在这个特定的情况下，交叉验证表明k = 7的值在这个特定的数据集上效果最好(对应于图中的峰值)。如果我们使用超过5次折叠，我们可能会看到一个更平滑(即噪音更小)的曲线。</font><br/></center>

***

**实践**

在实践中，人们更倾向于避免交叉验证，而倾向于使用单个验证分离，因为交叉验证在计算上很昂贵。人们倾向于使用50%-90%的训练数据进行训练，其余的用于验证。然而，这取决于多个因素:例如，如果超参数的数量很大，您可能更倾向于使用更大的验证分割。如果验证集中的示例数量很小(可能只有几百个左右)，那么使用交叉验证会更安全。在实践中，你可以看到的典型折叠数是3倍，5倍或10倍交叉验证。

<br/>

![图片](https://cs231n.github.io/assets/crossval.jpeg)

<center><font size="3">常见的数据分割。给出了训练集和测试集。训练集被分成多个折叠(例如这里的5个折叠)。折叠1-4就是训练集。另外一个折叠(例如黄色的折叠5)被表示为验证折叠，用于调优超参数。交叉验证更进一步，迭代选择哪个折叠是验证折叠，分别是1-5。这被称为5倍交叉验证。在最后，一旦模型训练好并且所有最佳超参数都确定了，就会在测试数据(红色)上对模型进行一次评估。</font><br/></center>

***

**最近邻分类器的优缺点**

最近邻分类器的一些优点和缺点值得思考。显然，它的一个优点是实现和理解非常简单。此外，分类器不需要花费时间来训练，因为所需要的只是存储和可能的索引训练数据。然而，我们在测试时付出了计算成本，因为分类测试示例需要与每个单独的训练示例进行比较。这是南辕北辙的，因为在实践中，我们通常更关心测试时间的效率而不是训练时间的效率。事实上，我们稍后将在本课程中开发的深度神经网络将这种权衡转移到另一个极端:训练它们非常昂贵，但一旦训练完成，分类一个新的测试示例就非常便宜。这种操作方式在实践中更可取。

顺便说一句，最近邻分类器的计算复杂性是一个活跃的研究领域，有几种 **近似近邻(Approximate Nearest Neighbor)** 算法和库可以加速数据集中的最近邻查找(例如[FLANN](https://github.com/flann-lib/flann))。这些算法允许人们在检索过程中权衡最近邻检索的正确性及其空间、时间复杂性，并且通常依赖于预处理、索引阶段，包括构建kdtree或运行k-means算法。

最近邻分类器有时在某些设置中可能是一个很好的选择(特别是如果数据是低维的)，但它很少适合用于实际的图像分类设置。其中一个问题是，图像是高维对象(即它们通常包含许多像素)，在高维空间中的距离可能非常违反直觉。下图说明了我们上面开发的基于像素的L2相似性与感知相似性非常不同:

<br/>

![图片](https://cs231n.github.io/assets/samenorm.png)

<center><font size="3">高维数据(尤其是图像)上基于像素的距离可能非常不直观。一张原始图像(左)和它旁边的其他三张图像，根据L2像素距离，它们都离它同样远。显然，像素级距离与感知或语义相似性完全不对应。</font><br/></center>

<br/>

> 此处的图片是经过精确计算处理的，因此计算L2距离时会得到完全相同的结果。

这里还有一个可视化的例子来说服你，使用像素差异来比较图像是不够的。我们可以使用一种名为[t-SNE](https://lvdmaaten.github.io/tsne/)的可视化技术来获取CIFAR-10图像，并将它们嵌入二维中，以便最好地保存它们的(局部)成对距离。在这个可视化中，根据我们上面谈及的L2像素级距离，显示在附近的图像被认为非常近:

<br/>

![图片](https://cs231n.github.io/assets/pixels_embed_cifar10_big.jpg)

<center><font size="3">用t-SNE嵌入二维CIFAR-10图像。基于L2像素距离，在此图像上较近的图像被认为是近的。注意背景的强烈影响，而不是语义类的差异。</font><br/></center>

<br/>

特别要注意的是，彼此靠近的图像更多的是图像的一般颜色分布或背景类型的函数，而不是它们的语义标识。例如，一只狗可以被视作离青蛙很近，因为它们恰好都在白色背景上。理想情况下，我们希望所有10个类的图像都能形成自己的**聚类（cluster）**，这样同一类的图像就会彼此靠近，而不考虑不相关的特征和变化(如背景)。然而，要获得这个属性，我们必须<mark>超越原始像素</mark>。

## 总结·Summary

总而言之:

- 我们介绍了**图像分类**的问题，在这个问题中，我们给出了一组图像，这些图像都被标记为单一类别。然后，我们被要求为一组新的测试图像预测这些类别，并测量预测的准确性。

- 我们引入了一个简单的分类器，称为**最近邻分类器**。我们看到有多个超参数(比如k的值，或者用于比较示例的距离类型)与这个分类器相关联，并且没有明显的方法来选择它们。

- 我们看到，设置这些超参数的正确方法是将训练数据分为两个:一个训练集和一个假测试集，我们称之为**验证集**。我们尝试不同的超参数值，并在验证集中保留导致最佳性能的值。

- 如果遇到缺乏训练数据的问题，我们讨论了一个称为**交叉验证**的过程，它可以减少在估计最优超参数时的噪声。

- 一旦找到了最好的超参数，我们就固定它们，并在实际测试集上进行**唯一一次评估**。

- 我们看到，最近邻可以在CIFAR-10上为我们提供大约40%的准确率。它很容易实现，但需要我们存储整个训练集，并且在测试图像上的评估成本很高。

- 最后，我们发现在原始像素值上使用L1或L2距离是不够的，因为距离与图像的背景和颜色分布的相关性比其语义内容更强。

在接下来的课程中，我们将着手解决这些挑战，并最终达到90%的精度的解决方案，使我们能够在学习完成后完全丢弃训练集。并且它们将允许我们在不到一毫秒的时间内评估测试图像。

## 总结：kNN的实践应用·Summary: Applying kNN in practice

如果你想在实践中应用kNN(希望不是在图像上，或者只是作为基线)，请按照以下步骤进行:

1. **预处理数据**:将数据中的特征归一化(例如图像中的一个像素)，使其具有零均值和单位方差。我们将在后面的部分中更详细地讨论这一点，在本节中选择不讨论数据规范化，因为图像中的像素通常是同构的，并且没有表现出广泛的不同分布，从而减轻了数据规范化的需要。

2. 如果您的数据是非常高维的，可以考虑使用**降维技术**，如PCA， NCA，甚至是随机投影。

3. 将训练数据随机分成训练、验证板块。根据经验，通常会有70-90%的数据用于训练板块。该设置取决于您有多少超参数，以及您希望它们具有多大的影响。如果有许多超参数需要估计，为了有效地估计它们，您应该宁可使用更大的验证集。如果您担心验证数据的大小，最好将训练数据分成折叠并执行交叉验证。如果你能负担得起计算预算，那么使用交叉验证总是更安全的(折叠次数越多越好，但成本更高)。

4. 在验证数据上训练和评估kNN分类器(如果进行交叉验证，则对所有折叠进行操作)对于k的选择(例如越多越好)以及跨不同的距离类型(L1和L2是很好的候选方案)。

5. 如果你的kNN分类器运行时间太长，可以考虑使用**近似最近邻库**(例如FLANN)来加速检索(以牺牲一些准确性为代价)。

6. 注意给出最佳结果的超参数。有一个问题是你是否应该使用带有最佳超参数的完整训练集，因为如果你将验证数据折叠到你的训练集中，最佳超参数可能会改变(因为数据的大小会更大)。在实践中，在最终的分类器中不使用验证数据，并认为它在估计超参数时被销毁是更干净的。在测试集中评估最佳模型。报告测试集的准确性，并将结果声明为kNN分类器在数据上的性能。

### 拓展阅读·Further Reading

下面是一些(可选的)链接，您可能会觉得有兴趣进一步阅读:

- [《关于机器学习的几件有用的事情》](https://homes.cs.washington.edu/~pedrod/papers/cacm12.pdf)，特别是第6节，但整篇论文都是强烈推荐阅读的。

- [《识别和学习对象类别》](https://people.csail.mit.edu/torralba/shortCourseRLOC/index.html)， ICCV 2005的一个关于对象分类的短期课程。
